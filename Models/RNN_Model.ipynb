{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cepdnaclk/e19-co544-Bitcoin-Cost-Forecast-System/blob/main/Models/RNN_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7EcAnWxoT92d"
      },
      "source": [
        "# Import Necessary Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "O1FG7VX1Tjzy",
        "outputId": "9edf16ef-f36f-4d04-df20-17b105503fbd"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "        <script type=\"text/javascript\">\n",
              "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
              "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
              "        if (typeof require !== 'undefined') {\n",
              "        require.undef(\"plotly\");\n",
              "        requirejs.config({\n",
              "            paths: {\n",
              "                'plotly': ['https://cdn.plot.ly/plotly-2.24.1.min']\n",
              "            }\n",
              "        });\n",
              "        require(['plotly'], function(Plotly) {\n",
              "            window._Plotly = Plotly;\n",
              "        });\n",
              "        }\n",
              "        </script>\n",
              "        "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import warnings  # Import the warnings module\n",
        "warnings.filterwarnings(\"ignore\")  # Ignore all warnings\n",
        "\n",
        "import numpy as np  # Import numpy for numerical computing\n",
        "import pandas as pd  # Import pandas for data manipulation\n",
        "import statsmodels.api as sm  # Import statmodels for statistical models\n",
        "from scipy import stats  # Import stats from SciPy for statistical functions\n",
        "from sklearn.metrics import mean_squared_error  # Import mean_squared_error from sklearn for model evaluation\n",
        "from math import sqrt  # Import sqrt from math for square root function\n",
        "from random import randint  # Import randint from random for generating random integers\n",
        "\n",
        "from keras.models import Sequential  # Import Sequential from keras for sequential model\n",
        "from keras.layers import Dense  # Import Dense from keras for fully connected layers\n",
        "from keras.layers import LSTM  # Import LSTM from keras for LSTM Layers\n",
        "from keras.layers import GRU  # Import GRU from keras for GRU layers\n",
        "from keras.callbacks import EarlyStopping  # Import EarlyStopping from keras for early stopping during model training\n",
        "from keras import initializers  # Import initializers from keras for initializing model parameters\n",
        "\n",
        "from matplotlib import pyplot as plt  # Import pyplot from matplotlib for plotting\n",
        "from datetime import datetime  # Import datetime for date and time operations\n",
        "from datetime import date # Import the date class from the datetime module\n",
        "\n",
        "import plotly.offline as py  # Import offline module from plotly for offline plotting\n",
        "import plotly.graph_objs as go  # Import graph_objs from plotly for creating plots\n",
        "py.init_notebook_mode(connected=True)  # Initialize plotly notebook mode\n",
        "\n",
        "# %matplotlib inline  # Magic command to display matplotlib plots inline in Jupyter notebooks\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tAu3dlMa1A5Z"
      },
      "source": [
        "# Import the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "WKm_27f41Izp"
      },
      "outputs": [],
      "source": [
        "import yfinance as yf  # Import the yfinance module, which allows us to download historical market data from yahoo finance\n",
        "\n",
        "# Define the ticker symbol for BitCoin\n",
        "ticker = 'BTC-USD'  # Assign the string 'BTC-USD' to the variable 'ticker'.\n",
        "\n",
        "# Get historical market data\n",
        "data = yf.Ticker(ticker).history(period = 'max')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L0SkPVDzuSiV"
      },
      "source": [
        "# Average Price"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JRBNLQWHuYa1",
        "outputId": "7fd6ab8c-05c5-49bd-969a-7c13551cf7a2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Date\n",
              "2014-09-17 00:00:00+00:00    457.334015\n",
              "2014-09-18 00:00:00+00:00    436.911062\n",
              "2014-09-19 00:00:00+00:00    419.823580\n",
              "2014-09-20 00:00:00+00:00    416.734836\n",
              "2014-09-21 00:00:00+00:00    413.700159\n",
              "Name: Weighted_Price, dtype: float64"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Group the data by the 'Date' column\n",
        "group = data.groupby('Date')\n",
        "\n",
        "# Calculate the product of price and volume\n",
        "data['PV'] = data['Close'] * data['Volume']\n",
        "\n",
        "# Calculate the cumulative sum of volume\n",
        "data['cumulative_volume'] = data['Volume'].cumsum()\n",
        "\n",
        "# Calculate the cumulative sum of PV\n",
        "data['cumulative_PV'] = data['PV'].cumsum()\n",
        "\n",
        "# Calculate VWAP\n",
        "data['Weighted_Price'] = data['cumulative_PV'] / data['cumulative_volume']\n",
        "\n",
        "Daily_Price = group['Weighted_Price'].mean()\n",
        "\n",
        "Daily_Price.head()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rTuW84iNAi72",
        "outputId": "4b361cf3-2456-4ca9-890d-12959d6e15db"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Date\n",
              "2024-05-17 00:00:00+00:00    29673.378562\n",
              "2024-05-18 00:00:00+00:00    29683.629636\n",
              "2024-05-19 00:00:00+00:00    29695.219963\n",
              "2024-05-20 00:00:00+00:00    29725.323465\n",
              "2024-05-21 00:00:00+00:00    29760.808104\n",
              "Name: Weighted_Price, dtype: float64"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Daily_Price.tail()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DT5e87WHBOQY"
      },
      "source": [
        "# Split Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0t1wXs7WBSu_",
        "outputId": "737f2160-f5fe-454d-bb46-e914509f215f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3535\n",
            "371\n",
            "3164 371\n"
          ]
        }
      ],
      "source": [
        "# Define two dates\n",
        "d0 = date(2014, 9, 17)  # Start date\n",
        "d1 = date(2024, 5, 21)  # End date\n",
        "\n",
        "# Calculate the difference between the two dates\n",
        "delta = d1 - d0  # This will return a time delta object\n",
        "\n",
        "# Get the number of days from the timedelta object and add 1\n",
        "days_look = delta.days + 1  # The '+ 1' is to include both end dates in the count\n",
        "\n",
        "# Print the result\n",
        "print(days_look)\n",
        "\n",
        "# Repeat the process for a different date range\n",
        "d0 = date(2023, 5, 17)\n",
        "d1 = date(2024, 5, 21)\n",
        "delta = d1 - d0\n",
        "days_from_train = delta.days + 1\n",
        "print(days_from_train)\n",
        "\n",
        "# Repeat the process for another date range\n",
        "'''d0 = date(2024, 5, 17)\n",
        "d1 = date(2024, 5, 21)\n",
        "delta = d1 - d0\n",
        "days_from_end = delta.days + 1\n",
        "print(days_from_end)'''\n",
        "\n",
        "# Create the training dataset\n",
        "# The training data is slice from the 'Daily_Price' series. The slice starts from 'days_look' - 'days_from_end' days before thr last record, and ends 'days_from_train' days before the last record.\n",
        "df_train = Daily_Price[len(Daily_Price) - days_look : len(Daily_Price) - days_from_train]\n",
        "\n",
        "# Create the testing dataset\n",
        "# The testing data is a slice from the 'Daily_Price' series. The slice starts from 'days_from_train' days before the last record and includes all records until the end of the series.\n",
        "df_test = Daily_Price[len(Daily_Price) - days_from_train :]\n",
        "\n",
        "# Print the length of the training and testing datasets\n",
        "print(len(df_train), len(df_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4YcfpDw7TGf"
      },
      "source": [
        "# EDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "lRZdpCfD7Wbt"
      },
      "outputs": [],
      "source": [
        "# Combine the training and testing datasets into a single DataFrame\n",
        "working_data = [df_train, df_test]\n",
        "working_data = pd.concat(working_data)\n",
        "\n",
        "# Reset the index of the DataFrame\n",
        "working_data = working_data.reset_index()\n",
        "\n",
        "# Convert the 'Date' column to datetime format\n",
        "working_data['Date'] = pd.to_datetime(working_data['Date'])\n",
        "\n",
        "# Set the 'Date' column as the index of the DataFrame\n",
        "working_data = working_data.set_index('Date')\n",
        "\n",
        "# Perform seasonal decomposition on the 'Weighted_Price' values using a frequency of 60 (assuming daily data)\n",
        "s = sm.tsa.seasonal_decompose(working_data.Weighted_Price.values, period = 60)\n",
        "\n",
        "#"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyPun31KfzgEAMUjkoeJfEPW",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
